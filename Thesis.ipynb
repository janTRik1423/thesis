{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f537b5",
   "metadata": {},
   "source": [
    "# Dust Detection from Remote Sensing Images\n",
    "In this notebook input images are used from MODIS Terra satellite from NASA. Here one sample .hdf file is used for input.\n",
    "There is one data folder where the .hdf file is located. That file is downloaded from NASA LAADS DAAC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd6799",
   "metadata": {},
   "source": [
    "##### All the Necessary packages and libraries are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa68f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import cspline2d\n",
    "\n",
    "import imageio as img\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from satpy import Scene, MultiScene, available_readers, available_writers, find_files_and_readers\n",
    "from satpy.readers import modis_l1b, modis_l2\n",
    "from satpy.writers import get_enhanced_image\n",
    "from satpy.composites import GenericCompositor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyresample import geometry\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "import tensorflow as tf\n",
    "# import statements\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms, models\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torchvision\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# From local helper files\n",
    "from helper_evaluation import set_all_seeds, set_deterministic, compute_confusion_matrix\n",
    "from helper_train import train_model\n",
    "from helper_plotting import plot_training_loss, plot_accuracy, show_examples, plot_confusion_matrix\n",
    "from helper_dataset import UnNormalize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# from utils import load_checkpoint, save_checkpoint, ensure_dir\n",
    "# from model import MyModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c907c38",
   "metadata": {},
   "source": [
    "## Module 1: Remote Sensing MODIS Data\n",
    "##### Checking the directory to find the location of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1744ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# LOADING DATASET\n",
    "#####################\n",
    "\n",
    "def content_from_path(path):\n",
    "    return os.listdir(path)\n",
    "\n",
    "def generate_data_from_path(path):\n",
    "    images = []\n",
    "    dataset_path = content_from_path(path)\n",
    "    \n",
    "    for item in dataset_path:\n",
    "        images.append((\"Yes\", item))\n",
    "        \n",
    "    return images\n",
    "     \n",
    "def generate_data_from_folder():\n",
    "    images = []\n",
    "    \n",
    "    for item in dataset_path:\n",
    "        path = 'nasa' + '/' + item\n",
    "        if os.path.isdir(path):  \n",
    "            image = os.listdir(path)\n",
    "            images.append((\"Yes\", str(path + '/' + image[0])))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# MAKING DATAFRAME\n",
    "#####################\n",
    "\n",
    "images = generate_data_from_path('nasa-calibrated-resize');\n",
    "dust_df = pd.DataFrame(data=images, columns=[\"Dust\", \"image\"])\n",
    "dust_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8806669",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# MAKING HORIZONTAL SPLITTED DATASET\n",
    "##################################################\n",
    "\n",
    "counter = 0\n",
    "for item in dust_df['image']:\n",
    "    \n",
    "    input_path = \"nasa-calibrated-resize/\" + item\n",
    "    if input_path.endswith('DS_Store') or os.path.isdir(input_path):\n",
    "        continue\n",
    "    outputPath = \"horizontal/\"\n",
    "    \n",
    "    img = cv2.imread(input_path)\n",
    "    im = Image.open(input_path)\n",
    "    x_width, y_height = im.size\n",
    "    # print(x_width, y_height)\n",
    "    \n",
    "    outputFileFormat = \"{0}-{1}.jpg\"\n",
    "    baseName = \"cropped\"\n",
    "    \n",
    "    split = 10\n",
    "    edges = np.linspace(0, x_width, split + 1)\n",
    "    # print(edges)\n",
    "    # print(edges[:-1])\n",
    "    # print(edges[1:])\n",
    "    for start, end in zip(edges[:-1], edges[1:]):\n",
    "        box = (start, 0, end, y_height)\n",
    "        a = im.crop(box)\n",
    "        x_width, y_height = a.size\n",
    "        # print(x_width, y_height)\n",
    "        a.load()\n",
    "        outputName = os.path.join(outputPath, outputFileFormat.format(baseName, counter + 1))\n",
    "        counter = counter + 1\n",
    "        # print(outputName)\n",
    "        a.save(outputName, \"JPEG\")\n",
    "        \n",
    "horizontal_images = generate_data_from_path('horizontal');\n",
    "dust_df_horizontal = pd.DataFrame(data=horizontal_images, columns=[\"Dust\", \"image\"])\n",
    "dust_df_horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dust_df_horizontal['image']:\n",
    "    \n",
    "    input_path = \"horizontal/\" + item\n",
    "    if input_path.endswith('DS_Store') or os.path.isdir(input_path):\n",
    "        continue\n",
    "    \n",
    "    img = cv2.imread(input_path)\n",
    "    im = Image.open(input_path)\n",
    "    # im.show()\n",
    "    x_width, y_height = im.size\n",
    "    print(x_width, y_height)\n",
    "    # print(img.shape)\n",
    "    # print(input_path)\n",
    "    if x_width != 128:\n",
    "        print(input_path)\n",
    "        os.remove(input_path)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6cf43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b552046",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# MAKING VERTICAL SPLITTED DATASET\n",
    "##################################################\n",
    "\n",
    "counter = 0\n",
    "for item in dust_df_horizontal['image']:\n",
    "    \n",
    "    input_path = \"horizontal/\" + item\n",
    "    if input_path.endswith('DS_Store') or os.path.isdir(input_path):\n",
    "        continue\n",
    "    outputPath = \"horizontal/final\"\n",
    "    \n",
    "    img = cv2.imread(input_path)\n",
    "    im = Image.open(input_path)\n",
    "    x_width, y_height = im.size\n",
    "    # print(x_width, y_height)\n",
    "    \n",
    "    outputFileFormat = \"{0}-{1}.jpg\"\n",
    "    baseName = \"cropped\"\n",
    "    \n",
    "    split = 15\n",
    "    edges = np.linspace(0, y_height, split + 1)\n",
    "    # print(edges)\n",
    "    # print(edges[:-1])\n",
    "    # print(edges[1:])\n",
    "    for start, end in zip(edges[:-1], edges[1:]):\n",
    "        box = (0, start, x_width, end)\n",
    "        a = im.crop(box)\n",
    "        a.load()\n",
    "        outputName = os.path.join(outputPath, outputFileFormat.format(baseName, counter + 1))\n",
    "        counter = counter + 1\n",
    "        # print(outputName)\n",
    "        a.save(outputName, \"JPEG\")\n",
    "        \n",
    "final_images = generate_data_from_path('horizontal/final');\n",
    "dust_df_final = pd.DataFrame(data=final_images, columns=[\"Dust\", \"image\"])\n",
    "dust_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7daa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dust_df_final['image']:\n",
    "    \n",
    "    input_path = \"horizontal/final/\" + item\n",
    "    if input_path.endswith('DS_Store') or os.path.isdir(input_path):\n",
    "        continue\n",
    "    count = 1\n",
    "    img = cv2.imread(input_path)\n",
    "    im = Image.open(input_path)\n",
    "    # im.show()\n",
    "    x_width, y_height = im.size\n",
    "    print(x_width, y_height)\n",
    "    # print(item.index)\n",
    "    if y_height != 128:\n",
    "        print(img.shape)\n",
    "        os.remove(input_path)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc6ef35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dust</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>cropped-15032.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>cropped-8525.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>cropped-7616.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>cropped-6508.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>cropped-995.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19136</th>\n",
       "      <td>Yes</td>\n",
       "      <td>cropped-9622.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19137</th>\n",
       "      <td>Yes</td>\n",
       "      <td>cropped-6511.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19138</th>\n",
       "      <td>Yes</td>\n",
       "      <td>cropped-14335.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19139</th>\n",
       "      <td>Yes</td>\n",
       "      <td>cropped-754.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19140</th>\n",
       "      <td>Yes</td>\n",
       "      <td>cropped-12744.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19141 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dust              image\n",
       "0      Yes  cropped-15032.jpg\n",
       "1      Yes   cropped-8525.jpg\n",
       "2      Yes   cropped-7616.jpg\n",
       "3      Yes   cropped-6508.jpg\n",
       "4      Yes    cropped-995.jpg\n",
       "...    ...                ...\n",
       "19136  Yes   cropped-9622.jpg\n",
       "19137  Yes   cropped-6511.jpg\n",
       "19138  Yes  cropped-14335.jpg\n",
       "19139  Yes    cropped-754.jpg\n",
       "19140  Yes  cropped-12744.jpg\n",
       "\n",
       "[19141 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################\n",
    "# MAKING FINAL DATAFRAME\n",
    "##########################################\n",
    "\n",
    "images = generate_data_from_path('horizontal/final/');\n",
    "dust_df_final_calibrated = pd.DataFrame(data=images, columns=[\"Dust\", \"image\"])\n",
    "dust_df_final_calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858dcc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dust_df_final_calibrated['image']:\n",
    "    \n",
    "    input_path = \"horizontal/final/\" + item\n",
    "    if input_path.endswith('DS_Store') or os.path.isdir(input_path):\n",
    "        continue\n",
    "    count = 1\n",
    "    img = cv2.imread(input_path)\n",
    "    im = Image.open(input_path)\n",
    "    # im.show()\n",
    "    x_width, y_height = im.size\n",
    "    print(x_width, y_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff06766-a1d5-4043-9d82-ad54d7246cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 15\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0203902f-7a6d-46ee-9ab4-8d1b2bce89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DustDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "\n",
    "        # print(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "223dd4f6-c1bb-435e-ad6e-b1478ea03d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([256, 3, 128, 128])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Class labels of 10 examples: tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### FINAL DUST DATASET\n",
    "##########################\n",
    "\n",
    "# resize_transform = torchvision.transforms.Compose(\n",
    "#     [torchvision.transforms.Resize((32, 32)),\n",
    "#      torchvision.transforms.ToTensor(),\n",
    "#      torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                      ])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([       \n",
    "    torchvision.transforms.ToTensor(),                \n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load Data\n",
    "dataset = DustDataset(\n",
    "    csv_file=\"dataset.csv\",\n",
    "    root_dir=\"horizontal/dataset/\",\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "train_set, valid_set, test_set = torch.utils.data.random_split(dataset, [256, 30, 33])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13eacef-51ba-4684-926f-1f606c55f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetDust(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(256 * 6 * 6, 4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(4096, 4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "941b8c90-8ab2-4bc1-81ed-5008a29d9442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rafi/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch 0000/0001 | Loss: 0.6909\n",
      "Epoch: 001/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 0.14 min\n",
      "Epoch: 002/015 | Batch 0000/0001 | Loss: 0.6627\n",
      "Epoch: 002/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 0.28 min\n",
      "Epoch: 003/015 | Batch 0000/0001 | Loss: 0.6168\n",
      "Epoch: 003/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 0.41 min\n",
      "Epoch: 004/015 | Batch 0000/0001 | Loss: 0.5646\n",
      "Epoch: 004/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 0.54 min\n",
      "Epoch: 005/015 | Batch 0000/0001 | Loss: 0.5160\n",
      "Epoch: 005/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 0.67 min\n",
      "Epoch: 006/015 | Batch 0000/0001 | Loss: 0.4764\n",
      "Epoch: 006/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 0.80 min\n",
      "Epoch: 007/015 | Batch 0000/0001 | Loss: 0.4521\n",
      "Epoch: 007/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 0.93 min\n",
      "Epoch: 008/015 | Batch 0000/0001 | Loss: 0.4728\n",
      "Epoch: 008/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 1.06 min\n",
      "Epoch: 009/015 | Batch 0000/0001 | Loss: 0.5142\n",
      "Epoch: 009/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 1.19 min\n",
      "Epoch: 010/015 | Batch 0000/0001 | Loss: 0.4849\n",
      "Epoch: 010/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 1.32 min\n",
      "Epoch: 011/015 | Batch 0000/0001 | Loss: 0.4685\n",
      "Epoch: 011/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 1.46 min\n",
      "Epoch: 012/015 | Batch 0000/0001 | Loss: 0.4696\n",
      "Epoch: 012/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 1.59 min\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 013/015 | Batch 0000/0001 | Loss: 0.4716\n",
      "Epoch: 013/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 1.72 min\n",
      "Epoch: 014/015 | Batch 0000/0001 | Loss: 0.4711\n",
      "Epoch: 014/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 1.85 min\n",
      "Epoch: 015/015 | Batch 0000/0001 | Loss: 0.4709\n",
      "Epoch: 015/015 | Train: 81.25% | Validation: 73.33%\n",
      "Time elapsed: 1.98 min\n",
      "Total Training Time: 1.98 min\n",
      "Test accuracy 75.76%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlhUlEQVR4nO3de3xU5b3v8c+PSQJJQCSAl0I0wSIWNIBcDKAHqJsWFME7ULeXo+fFYXusWo5bsbbuult7sMf2uG2plLYWrWxQ61bpS62KreKlCtgCcr8ZSwSRi4BJEJLwO3/MShzCBAJkZdYw3/frlVdmPfPMmh/LkS/PWmuex9wdERGRqGmV6gJERESSUUCJiEgkKaBERCSSFFAiIhJJCigREYmkrFQXcKRatWrlubm5qS5DRESaSVVVlbv7QQOmtAuo3NxcKisrU12GiIg0EzPbk6xdp/hERCSSQg0oMxtpZqvNbJ2ZTUny/L+a2eLgZ5mZ1ZpZQZg1iYhIerCwZpIwsxiwBhgBlAMLgQnuvqKR/pcA33H3rx9qv/n5+a5TfCIixw8zq3L3/IbtYV6DGgisc/cNQQFzgLFA0oACJgCzQ6xHRCKsurqa8vJyvvjii1SXIiFp06YNXbt2JTs7u0n9wwyoLsDGhO1y4LxkHc0sDxgJ3BJiPSISYeXl5bRr146ioiLMLNXlSDNzd7Zv3055eTnFxcVNek2Y16CSfcIaO594CfC2u+9IuiOziWa2yMwW1dTUNFuBIhIdX3zxBR07dlQ4HafMjI4dOx7RCDnMgCoHChO2uwKbGuk7nkOc3nP3Ge7e3937Z2Ud26Bv1nsfcfucvx/TPkQkHAqn49uR/vcNM6AWAt3NrNjMcoiH0NyGncysPTAUeD7EWupt+3wfzy/ZxK6q6pZ4OxEROUqhBZS71xC/pvQysBJ4yt2Xm9kkM5uU0PUy4BV3b5Fb887rVoA7LCxLejZRRDKYmXHttdfWb9fU1NC5c2dGjx4NwNy5c5k6deoh97Fp0yauvPJKAGbOnMkttxzZpfUf//jHh+1zww038Ic//OGw/dq2bXtE7x01oX4Pyt1fdPcz3f0Md78/aJvu7tMT+sx09/Fh1pGoT+GJ5MRa8d6H21vqLUUkTeTn57Ns2TL27IlPbPDqq6/SpUuX+ufHjBnDlCkHfaXzAF/5yleaFB6NaUpAZYqMm0miTXaMPoUnsuBDjaBE5GCjRo3ihRdeAGD27NlMmDCh/rnEEdENN9zArbfeyuDBg+nWrVt9KJWVlXH22WfXv2bjxo2MHDmSHj16cN9999W3X3rppfTr149evXoxY8YMAKZMmcKePXvo06cP11xzDQCPP/44JSUl9O7d+4DR3fz58w9676ZYvHgxpaWllJSUcNlll/HZZ58B8PDDD9OzZ09KSkoYPz4+ZnjjjTfo06cPffr0oW/fvnz++edNP5DNIO3m4msO53Ur4Jevr6dibw1tW2fkIRCJtPv+uJwVm3Y36z57fuUE/u2SXoftN378eP793/+d0aNHs3TpUm688UbefPPNpH03b97MW2+9xapVqxgzZkz9qb1ECxYsYNmyZeTl5TFgwAAuvvhi+vfvz6OPPkpBQQF79uxhwIABXHHFFUydOpVf/OIXLF68GIDly5dz//338/bbb9OpUyd27NhxRO+dzHXXXcfPf/5zhg4dyr333st9993HQw89xNSpU/nwww9p3bo1O3fuBODBBx9k2rRpDBkyhIqKCtq0adOk92guGTeCAjivuCO1+51Fug4lIg2UlJRQVlbG7Nmzueiiiw7Z99JLL6VVq1b07NmTLVu2JO0zYsQIOnbsSG5uLpdffjlvvfUWEB+x9O7dm9LSUjZu3MjatWsPeu2f//xnrrzySjp16gRAQcGXM8E15b0b2rVrFzt37mTo0KEAXH/99cyfP7/+z33NNdfwxBNPUHe39JAhQ5g8eTIPP/wwO3fu5Fjvoj5SGTl8OPf0E8lqZbz34Q6G9Tgp1eWISANNGemEacyYMdxxxx28/vrrbN/e+PXq1q1b1z9ubNq4hrdWmxmvv/468+bN469//St5eXkMGzYs6feD3L3RW7Ob8t5H4oUXXmD+/PnMnTuXH/7whyxfvpwpU6Zw8cUX8+KLL1JaWsq8efM466yzjvm9miojR1B5OVmc3aU975d9lupSRCSCbrzxRu69917OOeecY97Xq6++yo4dO9izZw/PPfccQ4YMYdeuXXTo0IG8vDxWrVrFu+++W98/Ozub6ur412AuvPBCnnrqqfqQTDzFdzTat29Phw4d6k9Z/v73v2fo0KHs37+fjRs3Mnz4cH7yk5+wc+dOKioqWL9+Peeccw533XUX/fv3Z9WqVcf0/kcqI0dQAD1Obse8lU0bFotIZunatSu33XZbs+zr/PPP59prr2XdunV861vfon///pxzzjlMnz6dkpISevToQWlpaX3/iRMnUlJSwrnnnsusWbO45557GDp0KLFYjL59+zJz5swmv3dVVRVdu3at3548eTKPPfYYkyZNoqqqim7duvG73/2O2tpa/vmf/5ldu3bh7nznO9/hxBNP5Pvf/z5/+ctfiMVi9OzZk1GjRjXLMWmq0GYzD0tzzWb+qzfW839eWsWSe79B+7ymTVwoIuFZuXIlX/va11JdhoQs2X/nxmYzz8hTfADdOse/wLZhW0WKKxERkWQyNqCKO8XD+sNtWltKRCSKMjagTivII9bK2LBVASUiEkUZG1A5Wa0o7JCrU3wiIhGVsQEF8etQGkGJiERTZgdUp3zKtleyf3963ckoIpIJMjqgijvn80X1fjbvbvoKjyJy/IrFYvTp04ezzz6bSy65pH5OuuY0ffp0Hn/88Wbb39atW8nOzuZXv/pVs+0zKjI6oLp1Cm4136rrUCICubm5LF68mGXLllFQUMC0adOa/T0mTZrEdddd12z7e/rppyktLWX27EYXJT8iNTU1zbKf5pDRAXVGZ91qLiLJDRo0iI8//hiAYcOGsWjRIgC2bdtGUVEREF9+4/LLL2fkyJF0796dO++8s/71bdu25Z577qmfELZuQtcf/OAHPPjgg/X7veuuuxg4cCBnnnlm/RREVVVVXH311ZSUlDBu3DjOO++8+vdvaPbs2fz0pz+lvLycjz/+mF27dlFUVMT+/fvr91VYWEh1dTXr169n5MiR9OvXjwsuuKB+6qIbbriByZMnM3z4cO666y4WLFjA4MGD6du3L4MHD2b16tWHreuVV15h0KBBnHvuuVx11VVUVBz7P/wzdqojgM7tWtO2dZZulBCJmpemwCcfNO8+TzkHRh16Ndw6tbW1vPbaa9x0002H7bt48WL+/ve/07p1a3r06MG3v/1tCgsLqayspLS0lPvvv58777yTX//613zve9876PU1NTUsWLCAF198kfvuu4958+bxy1/+kg4dOrB06VKWLVtGnz59kr73xo0b+eSTTxg4cCBXX301Tz75JJMnT6Z379688cYbDB8+nD/+8Y9885vfJDs7m4kTJzJ9+nS6d+/Oe++9x80338yf//xnANasWcO8efOIxWLs3r2b+fPnk5WVxbx58/jud7/LM88802hd27Zt40c/+hHz5s0jPz+fBx54gJ/97Gfce++9TTrejcnogDIzTivI4x87qlJdiohEQN1igWVlZfTr148RI0Yc9jUXXngh7du3B6Bnz5589NFHFBYWkpOTU79UfL9+/Xj11VeTvv7yyy+v71NWVgbAW2+9VT8X4Nlnn01JSUnS186ZM4err74aiK9jddNNNzF58mTGjRvHk08+yfDhw5kzZw4333wzFRUVvPPOO1x11VX1r9+7d2/946uuuopYLAbEl+W4/vrrWbt2LWZWP3ltY3W9++67rFixgiFDhgCwb98+Bg0adNhjdzihBpSZjQT+A4gBv3H3g/75YmbDgIeAbGCbuw8Ns6aGCgtyWa8RlEi0NHGk09zqrkHt2rWL0aNHM23aNG699VaysrLqT5k1XBYjcdmLWCxWfw0nOzu7fqmMxPaG6l6f2Kepc6TOnj2bLVu2MGvWLAA2bdrE2rVrGTNmDHfffTc7duzg/fff5+tf/zqVlZWceOKJ9YshNpSf/+VUeN///vcZPnw4zz77LGVlZQwbNuyQdbk7I0aMaLbrYHVCuwZlZjFgGjAK6AlMMLOeDfqcCPwSGOPuvYCrGu4nbKcV5LFxR5VuNReReu3bt+fhhx/mwQcfpLq6mqKiIt5//32AI1pe/Widf/75PPXUUwCsWLGCDz44+HTn6tWrqays5OOPP6asrIyysjLuvvtu5syZQ9u2bRk4cCC33XYbo0ePJhaLccIJJ1BcXMzTTz8NxENlyZIlSd9/165ddOnSBeCA2dMbq6u0tJS3336bdevWAfFrVWvWrDnm4xDmTRIDgXXuvsHd9wFzgLEN+nwL+C93/weAu38aYj1JnVaQx96a/Wyt2Hv4ziKSMfr27Uvv3r2ZM2cOd9xxB4888giDBw9m27Ztob/3zTffzNatWykpKeGBBx6gpKSk/jRindmzZ3PZZZcd0HbFFVfUj2LGjRvHE088wbhx4+qfnzVrFr/97W/p3bs3vXr14vnnn0/6/nfeeSd33303Q4YMoba29rB1de7cmZkzZzJhwgRKSkooLS1tlrWjQltuw8yuBEa6+/8Itq8FznP3WxL6PET81F4voB3wH+5+0BcEzGwiMBEgJyenX+J502P1+upPueF3C/nDpEH0Lyo4/AtEJBRabuNLtbW1VFdX06ZNG9avX8+FF17ImjVryMnJSfu6jmS5jTCvQSVbp7hhGmYB/YALgVzgr2b2rrsfMDZ09xnADIivB9WcRZ5WkAfAP3ZUKaBEJBKqqqoYPnw41dXVuDuPPPJIysMpFXWFGVDlQGHCdldgU5I+29y9Eqg0s/lAb+DYT142UZcOuZihO/lEJDLatWvX6PeeUqml6wrzGtRCoLuZFZtZDjAemNugz/PABWaWZWZ5wHnAyhBrOkjrrBinnNBGASUSAem2wrccmSP97xvaCMrda8zsFuBl4reZP+ruy81sUvD8dHdfaWZ/ApYC+4nfir4srJoaUxjcySciqdOmTRu2b99Ox44d62/PluOHu7N9+3batGnT5NeEdpNEWPLz872ysnm/t3TH00t4c+1W3vvuPzXrfkWk6aqrqykvLz/oe0Zy/GjTpg1du3YlOzv7gPZU3CSRNk4ryGPL7r18UV1Lm+xYqssRyUjZ2dkUFxenugyJkIyeLLZOYUEuAOWf7UlxJSIiUkcBxZe3mus6lIhIdCigiN8kAfDRds3JJyISFQoooHPb1uTlxCjbrhGUiEhUKKCIL7txesd8jaBERCJEARUo6pjHRxpBiYhEhgIqUNQpn3/sqKKmdn+qSxERERRQ9Yo65lGz39m0U18SFBGJAgVUoKhj/EvMZboOJSISCQqoQFEnBZSISJQooAIntWtNbnaMsm26UUJEJAoUUIH4reZ5GkGJiESEAipBUcd8BZSISEQooBKc3im+LlTt/vRagkRE5HikgEpQ3DGf6lpn007Nai4ikmoKqAR1d/Jt2Jb8NN/Ul1bx0gebW7IkEZGMpYBKcObJ7QBY88nnBz23r2Y/v3lzAzPfKWvhqkREMlOoAWVmI81stZmtM7MpSZ4fZma7zGxx8HNvmPUcTkF+Dp3btWb1loMDqmx7JTX7ncUbd7KvRtMhiYiELbQl380sBkwDRgDlwEIzm+vuKxp0fdPdR4dVx5HqcXI7VicZQa0JQmtvzX6WbdrFuad1aOnSREQySpgjqIHAOnff4O77gDnA2BDfr1n0OKUda7Z8ftCdfGu2VGAWf7zwwx0pqExEJLOEGVBdgI0J2+VBW0ODzGyJmb1kZr2S7cjMJprZIjNbVFNTE0at9Xqc0o69Nfv5R4Pl39du+ZyijvkUd8pnYdlnodYgIiLhBpQlaWv4BaO/Aae7e2/g58BzyXbk7jPcvb+798/KCu2sJABnnRK/UWL1J7sPaF/7aQVfPakt/U/vwPsf7WC/vislIhKqMAOqHChM2O4KbErs4O673b0iePwikG1mnUKs6bC6n9QOM1j9SUV9276a/ZRtq+TMk9syoLiAz6qq2bCt4hB7ERGRYxVmQC0EuptZsZnlAOOBuYkdzOwUs/iVHTMbGNSzPcSaDis3J8bpBXms3vLlCOrDbfE7+M48uR0DigoAeGd9SssUETnuhRZQ7l4D3AK8DKwEnnL35WY2ycwmBd2uBJaZ2RLgYWC8u6f83FmPU9qxKuFOvro7+L56UluKOubxtVNPYPaCjUSgVBGR41ao34Ny9xfd/Ux3P8Pd7w/aprv79ODxL9y9l7v3dvdSd38nzHqaqsfJ7SjbVskX1bVA/AaJVgZndG6LmXH9oNNZuXk3iz7SzRIiImEJ946DNNXntBPZ77Co7DPO796JNVsqOL1jPm2yYwCM7dOFH7+4ksfeKWNAUQEVe2t4a+02yrZX0iEvm3ZtssnNjtG1Qy7dg9kpRETkyCigkijt1pGcWCteX/0pA4o78Pb6bXyz1yn1z+fmxBg3oJDfvV3GyIfms35rBdW1B5/uG9e/kAeuLGnJ0kVEjhsKqCTycrI4r1sBr6/ZyuCvduTzL2q4+JxTD+hzw5BiFny4g4L8HIb1OImhZ3bm7C4nsGtPNRV7a/iiej/tc7NT9CcQEUl/lm4X+vPz872yMvxFBX/z5gZ+9MJKSrsVsGLTbhZ9bwQ5WZpbV0SkuZlZlbvnN2zX37iNGNbjJADe3bCDb/Q6ReEkItLC9LduI87onE/XDrkAB53eExGR8CmgGmFmfLPXKXRq25ohX03p5BYiIhlJ16AOYW9NLVV7a+mQn9Mi7ycikokauwalu/gOoXVWjNZZsVSXISKSkXSKT0REIkkBJSIikaSAEhGRSFJAiYhIJCmgREQkkhRQIiISSQooERGJJAWUiIhEUqgBZWYjzWy1ma0zsymH6DfAzGrN7Mow6xERkfQRWkCZWQyYBowCegITzKxnI/0eAF4OqxYREUk/YY6gBgLr3H2Du+8D5gBjk/T7NvAM8GmItYiISJoJM6C6ABsTtsuDtnpm1gW4DJh+qB2Z2UQzW2Rmi2pqapq9UBERiZ4mBZSZ5ZtZq+DxmWY2xswOt565JWlrOHX6Q8Bd7l57qB25+wx37+/u/bOyNL+tiEgmaOrf9vOBC8ysA/AasAgYB1xziNeUA4UJ212BTQ369AfmmBlAJ+AiM6tx9+eaWJeIiBynmnqKz9y9Crgc+Lm7X0b8xodDWQh0N7NiM8sBxgNzEzu4e7G7F7l7EfAH4GaFk4iIwBEElJkNIj5ieiFoO+Toy91rgFuI3523EnjK3Zeb2SQzm3S0BYuISGZo0oq6ZjYU+N/A2+7+gJl1A25391vDLrChllxRV0REwtfYirpHvOR7cLNEW3ff3VzFHQkFlIjI8aWxgGrqXXz/aWYnmFk+sAJYbWb/2txFioiI1GnqNaiewYjpUuBF4DTg2rCKEhERaWpAZQffe7oUeN7dqzn4O00iIiLNpqkB9SugDMgH5pvZ6UBKrkGJiEhmOOKbJOpfaJYV3EreonSThIjI8eVYb5Job2Y/q5sPz8x+Snw0JSIiEoqmnuJ7FPgcuDr42Q38LqyiREREmjoX3xnufkXC9n1mtjiEekRERICmj6D2mNn5dRtmNgTYE05JIiIiTR9BTQIeN7P2wfZnwPXhlCQiItLEgHL3JUBvMzsh2N5tZrcDS0OsTUREMtgRrajr7rsT5uCbHEI9IiIiwLEt+Z5sxVwREZFmcSwBpamOREQkNIe8BmVmn5M8iAzIDaUiERERDr8qbruWKkRERCTRsZziExERCU2oAWVmI81stZmtM7MpSZ4fa2ZLzWxxMMff+cn2IyIimeeoZzM/7I7NYsAaYARQDiwEJrj7ioQ+bYFKd3czKwGecvezDrVfzWYuInJ8OabZzI/SQGCdu29w933AHGBsYgd3r/AvEzIf3RkoIiKBMAOqC7AxYbs8aDuAmV1mZquAF4Abk+3IzCbWLfVRU9PiS1CJiEgKhBlQyb7Ie9AIyd2fDU7rXQr8MNmO3H2Gu/d39/5ZWU2dPlBERNJZmAFVDhQmbHcFNjXW2d3nA2eYWacQaxIRkTQRZkAtBLqbWbGZ5QDjgbmJHczsq2ZmweNzgRxge4g1iYhImgjtfJm715jZLcDLQAx41N2Xm9mk4PnpwBXAdWZWTXx9qXEe1m2FIiKSVkK7zTwsus1cROT4korbzEVERI6aAkpERCJJASUiIpGkgBIRkUhSQImISCQpoEREJJIUUCIiEkkKKBERiSQFlIiIRJICSkREIkkBJSIikaSAEhGRSFJAiYhIJCmgREQkkhRQIiISSQooERGJJAWUiIhEUqgBZWYjzWy1ma0zsylJnr/GzJYGP++YWe8w6xERkfQRWkCZWQyYBowCegITzKxng24fAkPdvQT4ITAjrHpERCS9hDmCGgisc/cN7r4PmAOMTezg7u+4+2fB5rtA1xDrERGRNBJmQHUBNiZslwdtjbkJeCnZE2Y20cwWmdmimpqaZixRRESiKivEfVuSNk/a0Ww48YA6P9nz7j6D4PRffn5+0n2IiMjxJcyAKgcKE7a7ApsadjKzEuA3wCh33x5iPSIikkbCPMW3EOhuZsVmlgOMB+YmdjCz04D/Aq519zUh1iIiImkmtBGUu9eY2S3Ay0AMeNTdl5vZpOD56cC9QEfgl2YGUOPu/cOqSURE0oe5p9clnfz8fK+srEx1GSIi0kzMrMrd8xu2ayYJERGJJAWUiIhEkgJKREQiSQElIiKRpIASEZFIUkCJiEgkKaBERCSSFFAiIhJJCigREYkkBZSIiESSAkpERCJJASUiIpGkgBIRkUhSQImISCQpoEREJJIUUCIiEkkKKBERiSQFlIiIRFKoAWVmI81stZmtM7MpSZ4/y8z+amZ7zeyOMGsREZH0khXWjs0sBkwDRgDlwEIzm+vuKxK67QBuBS4Nqw4REUlPYY6gBgLr3H2Du+8D5gBjEzu4+6fuvhCoDrEOERFJQ2EGVBdgY8J2edB2xMxsopktMrNFNTU1zVKciIhEW5gBZUna/Gh25O4z3L2/u/fPygrtrKSIiERImAFVDhQmbHcFNoX4fiIichwJM6AWAt3NrNjMcoDxwNwQ309ERI4joZ0vc/caM7sFeBmIAY+6+3IzmxQ8P93MTgEWAScA+83sdqCnu+8Oqy4REUkP5n5Ul4VSJj8/3ysrK1NdhoiINBMzq3L3/IbtmklCREQiSQElIiKRpIASEZFIUkCJiEgkKaBERCSSFFAiIhJJCigREYkkBZSIiESSAkpERCIp86YGf2kKfPJBqqsQETk+nHIOjJoayq41ghIRkUjSXHwiIpJSmotPRETSigJKREQiSQElIiKRpIASEZFIUkCJiEgkKaBERCSSFFAiIhJJafc9KDPbByw9xt10ArY1QzktTXW3LNXdstKx7nSsGaJXd4m75zRsTLuAag5mtsjd+6e6jiOluluW6m5Z6Vh3OtYM6VO3TvGJiEgkKaBERCSSMjWgZqS6gKOkuluW6m5Z6Vh3OtYMaVJ3Rl6DEhGR6MvUEZSIiEScAkpERCIp4wLKzEaa2WozW2dmU1JdTzJmVmhmfzGzlWa23MxuC9p/YGYfm9ni4OeiVNfakJmVmdkHQX2LgrYCM3vVzNYGvzukus5EZtYj4ZguNrPdZnZ7FI+3mT1qZp+a2bKEtkaPr5ndHXzWV5vZN1NTdaN1/18zW2VmS83sWTM7MWgvMrM9Ccd9esTqbvRzEfHj/WRCzWVmtjhoj8zxPoi7Z8wPEAPWA92AHGAJ0DPVdSWp81Tg3OBxO2AN0BP4AXBHqus7TO1lQKcGbT8BpgSPpwAPpLrOw3xGPgFOj+LxBv4bcC6w7HDHN/jMLAFaA8XBZz8Wobq/AWQFjx9IqLsosV8Ej3fSz0XUj3eD538K3Bu1493wJ9NGUAOBde6+wd33AXOAsSmu6SDuvtnd/xY8/hxYCXRJbVXHZCzwWPD4MeDS1JVyWBcC6939o1QXkoy7zwd2NGhu7PiOBea4+153/xBYR/z/gRaXrG53f8Xda4LNd4GuLV7YYTRyvBsT6eNdx8wMuBqY3aJFHYVMC6guwMaE7XIi/he/mRUBfYH3gqZbglMij0btVFnAgVfM7H0zmxi0nezumyEevsBJKavu8MZz4P+4UT/e0PjxTafP+43ASwnbxWb2dzN7w8wuSFVRh5Dsc5Eux/sCYIu7r01oi+TxzrSAsiRtkb3P3szaAs8At7v7buAR4AygD7CZ+DA9aoa4+7nAKOB/mdl/S3VBTWVmOcAY4OmgKR2O96GkxefdzO4BaoBZQdNm4DR37wtMBv7TzE5IVX1JNPa5SIvjDUzgwH+ERfZ4Z1pAlQOFCdtdgU0pquWQzCybeDjNcvf/AnD3Le5e6+77gV+TotMHh+Lum4LfnwLPEq9xi5mdChD8/jR1FR7SKOBv7r4F0uN4Bxo7vpH/vJvZ9cBo4BoPLogEp8i2B4/fJ34t58zUVXmgQ3wu0uF4ZwGXA0/WtUX5eGdaQC0EuptZcfCv5fHA3BTXdJDgHPFvgZXu/rOE9lMTul0GLGv42lQys3wza1f3mPhF8GXEj/H1QbfrgedTU+FhHfAvy6gf7wSNHd+5wHgza21mxUB3YEEK6kvKzEYCdwFj3L0qob2zmcWCx92I170hNVUe7BCfi0gf78A/AavcvbyuIdLHO9V3abT0D3AR8bvi1gP3pLqeRmo8n/ipgaXA4uDnIuD3wAdB+1zg1FTX2qDubsTvYloCLK87vkBH4DVgbfC7INW1Jqk9D9gOtE9oi9zxJh6gm4Fq4v9iv+lQxxe4J/isrwZGRazudcSv2dR9xqcHfa8IPj9LgL8Bl0Ss7kY/F1E+3kH7TGBSg76ROd4NfzTVkYiIRFKmneITEZE0oYASEZFIUkCJiEgkKaBERCSSFFAiIhJJCiiRY2BmFcHvIjP7VjPv+7sNtt9pzv2LRJ0CSqR5FAFHFFB1X448hAMCyt0HH2FNImlNASXSPKYCFwTr6XzHzGLBekcLg0lF/yeAmQ2z+Fpf/0n8y56Y2XPB5LrL6ybYNbOpQG6wv1lBW91ozYJ9L7P42lvjEvb9upn9weLrLM0KZiXBzKaa2Yqglgdb/OiIHIWsVBcgcpyYQnyNoNEAQdDscvcBZtYaeNvMXgn6DgTO9viSDAA3uvsOM8sFFprZM+4+xcxucfc+Sd7rcuITlfYGOgWvmR881xfoRXwOuLeBIWa2gviUPGe5u1uwMKBI1GkEJRKObwDXBauWvkd8OqLuwXMLEsIJ4FYzW0J8TaTChH6NOR+Y7fEJS7cAbwADEvZd7vGJTBcTP/W4G/gC+I2ZXQ5UHbxLkehRQImEw4Bvu3uf4KfY3etGUJX1ncyGEZ/Ac5C79wb+DrRpwr4bszfhcS3xFWtriI/aniG+mOGfjuDPIZIyCiiR5vE50C5h+2XgX4JlUzCzM4MZ3htqD3zm7lVmdhZQmvBcdd3rG5gPjAuuc3Umvrx3o7NmB+uKtXf3F4HbiZ8eFIk8XYMSaR5LgZrgVN1M4D+In177W3CjwlaSL3X/J2CSmS0lPgP2uwnPzQCWmtnf3P2ahPZngUHEZ5924E53/yQIuGTaAc+bWRvio6/vHNWfUKSFaTZzERGJJJ3iExGRSFJAiYhIJCmgREQkkhRQIiISSQooERGJJAWUiIhEkgJKREQiSQElIiKRpIASEZFIUkCJiEgkKaBERCSSFFAiIhJJCigREYkkBZSIiERS2q0HZWZ/Ajod4246AduaoZzm3peISCba5u4jGzZm5HpQZrbI3ftHbV8iIvIlneITEZFIUkCJiEgkZWpAzYjovkREJJCR16BERCT6MnUEJSIiEaeAEhGRSMq4gDKzkWa22szWmdmUI3jdo2b2qZktS2grMLNXzWxt8LtDOFWLiGSejAooM4sB04BRQE9ggpn1bOLLZwINv0g2BXjN3bsDrwXbIiLSDDIqoICBwDp33+Du+4A5wNimvNDd5wM7GjSPBR4LHj8GXNpMdYqIZLxMC6guwMaE7fKg7Wid7O6bAYLfJx3DvkREJEGmBZQladN99iIiEZRpAVUOFCZsdwU2HcP+tpjZqQDB70+PYV8iIpIg0wJqIdDdzIrNLAcYD8w9hv3NBa4PHl8PPH+M9YmISCDjZpIws4uAh4AY8Ki739/E180GhhFfXmML8G/Ac8BTwGnAP4Cr3L3hjRQiInIUMi6gREQkPWTaKT4REUkTCigREYkkBZSIiESSAkpERCJJASUiIpGkgBIJgZnVmtnihJ9mm0jYzIoSZ9UXOV5lpboAkePUHnfvk+oiRNKZRlAiLcjMyszsATNbEPx8NWg/3cxeM7Olwe/TgvaTzexZM1sS/AwOdhUzs1+b2XIze8XMcoP+t5rZimA/c1L0xxRpFgookXDkNjjFNy7hud3uPhD4BfFZTQgeP+7uJcAs4OGg/WHgDXfvDZwLLA/auwPT3L0XsBO4ImifAvQN9jMpnD+aSMvQTBIiITCzCndvm6S9DPi6u28ws2zgE3fvaGbbgFPdvTpo3+zuncxsK9DV3fcm7KMIeDVYKBMzuwvIdvcfmdmfgAri03A95+4VIf9RRUKjEZRIy/NGHjfWJ5m9CY9r+fJ68sXEV43uB7xvZrrOLGlLASXS8sYl/P5r8Pgd4rPrA1wDvBU8fg34FwAzi5nZCY3t1MxaAYXu/hfgTuBE4KBRnEi60L+uRMKRa2aLE7b/5O51t5q3NrP3iP8DcULQdivwqJn9K7AV+O9B+23ADDO7ifhI6V+AzY28Zwx4wszaE1+c8/+5+85m+vOItDhdgxJpQcE1qP7uvi3VtYhEnU7xiYhIJGkEJSIikaQRlIiIRJICSkREIkkBJSIikaSAEhGRSFJAiYhIJP1/oFyubQo4kCUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AlexNetDust(num_classes=2)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       mode='max',\n",
    "                                                       verbose=True)\n",
    "\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
    "    model=model,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_on='valid_acc',\n",
    "    logging_interval=100)\n",
    "\n",
    "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
    "                   num_epochs=NUM_EPOCHS,\n",
    "                   iter_per_epoch=len(train_loader),\n",
    "                   results_dir=None,\n",
    "                   averaging_iterations=200)\n",
    "plt.show()\n",
    "\n",
    "plot_accuracy(train_acc_list=train_acc_list,\n",
    "              valid_acc_list=valid_acc_list,\n",
    "              results_dir=None)\n",
    "plt.ylim([60, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c93fdc",
   "metadata": {},
   "source": [
    "##### Changing the folder to data to get access of the .hdf file\n",
    "This file is downloaded before from NASA LAADS DAAC. Changing the directory should be executed only once otherwise it will show error because it has already changed the directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d32e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory to data to get access of the file\n",
    "# os.chdir(os.path.join(os.getcwd(), 'data'))\n",
    "\n",
    "# Accessing file for processing\n",
    "filename = os.path.join(\"MOD021KM.A2021092.0020.006.2021092134055.hdf\")\n",
    "filenames = [filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208177f4",
   "metadata": {},
   "source": [
    "##### Loading data to scene object from SatPy. \n",
    "SatPy is used here for processing remote sensing images\n",
    "Printing available dataset names which is required for listing the bands\n",
    "Here total 36 bands information are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d19114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIS scene object using the file retrieved from data folder\n",
    "modis_scene = Scene(reader='modis_l1b', filenames=filenames)\n",
    "modis_scene.available_dataset_names()\n",
    "# modis_scene.unload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef3421c",
   "metadata": {},
   "source": [
    "##### Method: Band Details and Plotting\n",
    "This is the custom method which takes band no and color map as parameter and shows all the necessary information about that particular band. The second method plot_band() takes the band no as parameter and plot the band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_details(band_no, cmap):\n",
    "    \n",
    "    print(\"Band no: \", band_no)\n",
    "    print(\"Platform name: \", modis_scene[band_no].attrs['platform_name'])\n",
    "    print(\"Dimension: \", modis_scene[band_no].dims)\n",
    "    print(\"No of dimension: \", modis_scene[band_no].ndim)\n",
    "    print(\"Wavelength: \", modis_scene[band_no].wavelength)\n",
    "    print(\"Calibration: \", modis_scene[band_no].calibration)\n",
    "    print(\"Maximum value: \", modis_scene[band_no].max().values)\n",
    "    \n",
    "    modis_scene[band_no].plot.imshow(cmap=cmap)\n",
    "    plt.title(\"Band-{}\".format(band_no))\n",
    "\n",
    "def plot_band(band_no):\n",
    "\n",
    "    plt.figure()\n",
    "    modis_scene.load([band_no])\n",
    "    band_details(band_no, 'cividis')\n",
    "    modis_scene[band_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_no = '3'\n",
    "plot_band(band_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159231b",
   "metadata": {},
   "source": [
    "### Data Extraction\n",
    "Image data is extrcted from the metadata of MODIS hdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = modis_scene[band_no]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fec55e",
   "metadata": {},
   "source": [
    "### Resizing Image\n",
    "The dimension of input image is too high so the reduced dimension of image is used by resizing it to (128, 128) where original image dimension was (2030, 1354). Finally image value is normalized by dividing by 255. Image is first converted to matrix and then again to numpy array to match the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed99b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "\n",
    "image = resize(img_to_array(modis_scene[band_no]), (128, 128),  mode = 'constant', preserve_range = True)\n",
    "image = image/255.0\n",
    "image.shape\n",
    "image = np.matrix(image)\n",
    "image = np.array(image)\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the image after resizing\n",
    "plt.figure()\n",
    "plt.imshow(image, cmap = 'viridis')\n",
    "plt.title('Band - ' + band_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_scene.unload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce11fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
