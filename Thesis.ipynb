{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f537b5",
   "metadata": {},
   "source": [
    "# Dust Detection from Remote Sensing Images\n",
    "In this notebook input images are used from MODIS Terra satellite from NASA. Here one sample .hdf file is used for input.\n",
    "There is one data folder where the .hdf file is located. That file is downloaded from NASA LAADS DAAC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd6799",
   "metadata": {},
   "source": [
    "##### All the Necessary packages and libraries are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import cspline2d\n",
    "import imageio as img\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "from satpy import Scene, MultiScene, available_readers, available_writers, find_files_and_readers\n",
    "from satpy.readers import modis_l1b, modis_l2\n",
    "from satpy.writers import get_enhanced_image\n",
    "from satpy.composites import GenericCompositor\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyresample import geometry\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "import tensorflow as tf\n",
    "# import statements\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# from utils import load_checkpoint, save_checkpoint, ensure_dir\n",
    "# from model import MyModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c907c38",
   "metadata": {},
   "source": [
    "## Module 1: Remote Sensing MODIS Data\n",
    "##### Checking the directory to find the location of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# LOADING DATASET\n",
    "#####################\n",
    "\n",
    "def content_from_path(path):\n",
    "    return os.listdir(path)\n",
    "\n",
    "def generate_data_from_path(path):\n",
    "    images = []\n",
    "    dataset_path = content_from_path(path)\n",
    "    \n",
    "    for item in dataset_path:\n",
    "        images.append((\"Yes\", item))\n",
    "        \n",
    "    return images\n",
    "     \n",
    "def generate_data_from_folder():\n",
    "    images = []\n",
    "    \n",
    "    for item in dataset_path:\n",
    "        path = 'nasa' + '/' + item\n",
    "        if os.path.isdir(path):  \n",
    "            image = os.listdir(path)\n",
    "            images.append((\"Yes\", str(path + '/' + image[0])))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# MAKING DATAFRAME\n",
    "#####################\n",
    "\n",
    "images = generate_data_from_path('nasa-calibrated-resize');\n",
    "dust_df = pd.DataFrame(data=images, columns=[\"Dust\", \"image\"])\n",
    "dust_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8806669",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# MAKING HORIZONTAL SPLITTED DATASET\n",
    "##################################################\n",
    "\n",
    "counter = 0\n",
    "for item in dust_df['image']:\n",
    "    \n",
    "    input_path = \"nasa-calibrated-resize/\" + item\n",
    "    if input_path.endswith('DS_Store') or os.path.isdir(input_path):\n",
    "        continue\n",
    "    outputPath = \"horizontal/\"\n",
    "    \n",
    "    img = cv2.imread(input_path)\n",
    "    im = Image.open(input_path)\n",
    "    x_width, y_height = im.size\n",
    "    # print(x_width, y_height)\n",
    "    \n",
    "    outputFileFormat = \"{0}-{1}.jpg\"\n",
    "    baseName = \"cropped\"\n",
    "    \n",
    "    split = 10\n",
    "    edges = np.linspace(0, x_width, split + 1)\n",
    "    # print(edges)\n",
    "    # print(edges[:-1])\n",
    "    # print(edges[1:])\n",
    "    for start, end in zip(edges[:-1], edges[1:]):\n",
    "        box = (start, 0, end, y_height)\n",
    "        a = im.crop(box)\n",
    "        x_width, y_height = a.size\n",
    "        # print(x_width, y_height)\n",
    "        a.load()\n",
    "        outputName = os.path.join(outputPath, outputFileFormat.format(baseName, counter + 1))\n",
    "        counter = counter + 1\n",
    "        # print(outputName)\n",
    "        a.save(outputName, \"JPEG\")\n",
    "        \n",
    "horizontal_images = generate_data_from_path('horizontal');\n",
    "dust_df_horizontal = pd.DataFrame(data=horizontal_images, columns=[\"Dust\", \"image\"])\n",
    "dust_df_horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dust_df_horizontal['image']:\n",
    "    \n",
    "    input_path = \"horizontal/\" + item\n",
    "    if input_path.endswith('DS_Store') or os.path.isdir(input_path):\n",
    "        continue\n",
    "    \n",
    "    img = cv2.imread(input_path)\n",
    "    im = Image.open(input_path)\n",
    "    # im.show()\n",
    "    x_width, y_height = im.size\n",
    "    print(x_width, y_height)\n",
    "    # print(img.shape)\n",
    "    # print(input_path)\n",
    "    if x_width != 128:\n",
    "        print(input_path)\n",
    "        os.remove(input_path)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6cf43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b552046",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# MAKING VERTICAL SPLITTED DATASET\n",
    "##################################################\n",
    "\n",
    "counter = 0\n",
    "for item in dust_df_horizontal['image']:\n",
    "    \n",
    "    input_path = \"horizontal/\" + item\n",
    "    if input_path.endswith('DS_Store') or os.path.isdir(input_path):\n",
    "        continue\n",
    "    outputPath = \"horizontal/final\"\n",
    "    \n",
    "    img = cv2.imread(input_path)\n",
    "    im = Image.open(input_path)\n",
    "    x_width, y_height = im.size\n",
    "    # print(x_width, y_height)\n",
    "    \n",
    "    outputFileFormat = \"{0}-{1}.jpg\"\n",
    "    baseName = \"cropped\"\n",
    "    \n",
    "    split = 15\n",
    "    edges = np.linspace(0, y_height, split + 1)\n",
    "    # print(edges)\n",
    "    # print(edges[:-1])\n",
    "    # print(edges[1:])\n",
    "    for start, end in zip(edges[:-1], edges[1:]):\n",
    "        box = (0, start, x_width, end)\n",
    "        a = im.crop(box)\n",
    "        a.load()\n",
    "        outputName = os.path.join(outputPath, outputFileFormat.format(baseName, counter + 1))\n",
    "        counter = counter + 1\n",
    "        # print(outputName)\n",
    "        a.save(outputName, \"JPEG\")\n",
    "        \n",
    "final_images = generate_data_from_path('horizontal/final');\n",
    "dust_df_final = pd.DataFrame(data=final_images, columns=[\"Dust\", \"image\"])\n",
    "dust_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7daa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dust_df_final['image']:\n",
    "    \n",
    "    input_path = \"horizontal/final/\" + item\n",
    "    if input_path.endswith('DS_Store') or os.path.isdir(input_path):\n",
    "        continue\n",
    "    count = 1\n",
    "    img = cv2.imread(input_path)\n",
    "    im = Image.open(input_path)\n",
    "    # im.show()\n",
    "    x_width, y_height = im.size\n",
    "    print(x_width, y_height)\n",
    "    # print(item.index)\n",
    "    if y_height != 128:\n",
    "        print(img.shape)\n",
    "        os.remove(input_path)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# MAKING FINAL DATAFRAME\n",
    "##########################################\n",
    "\n",
    "images = generate_data_from_path('horizontal/final/');\n",
    "dust_df_final_calibrated = pd.DataFrame(data=images, columns=[\"Dust\", \"image\"])\n",
    "dust_df_final_calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858dcc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dust_df_final_calibrated['image']:\n",
    "    \n",
    "    input_path = \"horizontal/final/\" + item\n",
    "    if input_path.endswith('DS_Store') or os.path.isdir(input_path):\n",
    "        continue\n",
    "    count = 1\n",
    "    img = cv2.imread(input_path)\n",
    "    im = Image.open(input_path)\n",
    "    # im.show()\n",
    "    x_width, y_height = im.size\n",
    "    # print(x_width, y_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = 'nasa/'\n",
    "\n",
    "im_size = 60\n",
    "resize_images = []\n",
    "labels = [\"dust\"]\n",
    "\n",
    "for i in dataset_path:\n",
    "    data_path = path + str(i)\n",
    "    \n",
    "    # print(data_path)\n",
    "    if os.path.isdir(data_path):\n",
    "        filenames = [i for i in os.listdir(data_path)]\n",
    "        # print(filenames)\n",
    "        \n",
    "        for f in filenames:\n",
    "        \n",
    "            img = cv2.imread(data_path + \"/\" + f)\n",
    "\n",
    "            print(img)\n",
    "\n",
    "            img = cv2.resize(img, (im_size, im_size))\n",
    "\n",
    "            print(i)\n",
    "\n",
    "\n",
    "            resize_images.append(img)\n",
    "                \n",
    "resize_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a21cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67122b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(resize_images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype('float32') / 255.0\n",
    "plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "y = dust_df[\"Dust\"].values\n",
    "\n",
    "y_labelencoder = LabelEncoder()\n",
    "y = y_labelencoder.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "onehotencoder = OneHotEncoder()\n",
    "Y = onehotencoder.fit_transform(y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c93fdc",
   "metadata": {},
   "source": [
    "##### Changing the folder to data to get access of the .hdf file\n",
    "This file is downloaded before from NASA LAADS DAAC. Changing the directory should be executed only once otherwise it will show error because it has already changed the directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d32e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory to data to get access of the file\n",
    "# os.chdir(os.path.join(os.getcwd(), 'data'))\n",
    "\n",
    "# Accessing file for processing\n",
    "filename = os.path.join(\"MOD021KM.A2021092.0020.006.2021092134055.hdf\")\n",
    "filenames = [filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208177f4",
   "metadata": {},
   "source": [
    "##### Loading data to scene object from SatPy. \n",
    "SatPy is used here for processing remote sensing images\n",
    "Printing available dataset names which is required for listing the bands\n",
    "Here total 36 bands information are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d19114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIS scene object using the file retrieved from data folder\n",
    "modis_scene = Scene(reader='modis_l1b', filenames=filenames)\n",
    "modis_scene.available_dataset_names()\n",
    "# modis_scene.unload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef3421c",
   "metadata": {},
   "source": [
    "##### Method: Band Details and Plotting\n",
    "This is the custom method which takes band no and color map as parameter and shows all the necessary information about that particular band. The second method plot_band() takes the band no as parameter and plot the band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_details(band_no, cmap):\n",
    "    \n",
    "    print(\"Band no: \", band_no)\n",
    "    print(\"Platform name: \", modis_scene[band_no].attrs['platform_name'])\n",
    "    print(\"Dimension: \", modis_scene[band_no].dims)\n",
    "    print(\"No of dimension: \", modis_scene[band_no].ndim)\n",
    "    print(\"Wavelength: \", modis_scene[band_no].wavelength)\n",
    "    print(\"Calibration: \", modis_scene[band_no].calibration)\n",
    "    print(\"Maximum value: \", modis_scene[band_no].max().values)\n",
    "    \n",
    "    modis_scene[band_no].plot.imshow(cmap=cmap)\n",
    "    plt.title(\"Band-{}\".format(band_no))\n",
    "\n",
    "def plot_band(band_no):\n",
    "\n",
    "    plt.figure()\n",
    "    modis_scene.load([band_no])\n",
    "    band_details(band_no, 'cividis')\n",
    "    modis_scene[band_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_no = '3'\n",
    "plot_band(band_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159231b",
   "metadata": {},
   "source": [
    "### Data Extraction\n",
    "Image data is extrcted from the metadata of MODIS hdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = modis_scene[band_no]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fec55e",
   "metadata": {},
   "source": [
    "### Resizing Image\n",
    "The dimension of input image is too high so the reduced dimension of image is used by resizing it to (128, 128) where original image dimension was (2030, 1354). Finally image value is normalized by dividing by 255. Image is first converted to matrix and then again to numpy array to match the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed99b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "\n",
    "image = resize(img_to_array(modis_scene[band_no]), (128, 128),  mode = 'constant', preserve_range = True)\n",
    "image = image/255.0\n",
    "image.shape\n",
    "image = np.matrix(image)\n",
    "image = np.array(image)\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the image after resizing\n",
    "plt.figure()\n",
    "plt.imshow(image, cmap = 'viridis')\n",
    "plt.title('Band - ' + band_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_scene.unload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce11fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
